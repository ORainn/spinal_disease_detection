{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as tm\n",
    "import torchvision.transforms.functional as tf\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "sys.path.append('../code')\n",
    "sys.path.append('../../nn_tools/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.data_utils import read_dcms, get_spacing, read_annotation, SPINAL_DISC_ID, SPINAL_VERTEBRA_ID, rotate_point\n",
    "from core.visilization import visilize_coord, visilize_distmap, visilize_annotation\n",
    "from core.key_point import KeyPointAcc, KeyPointDataLoader, KeyPointModel, NullLoss, SpinalModelBase\n",
    "from core.key_point import KeyPointBCELossV2, SpinalModel, KeyPointBCELoss, KeyPointModelV2\n",
    "from core.structure import DICOM, Study, construct_studies\n",
    "from core.disease import DiseaseModelBase, DiseaseModel, DisDataLoader, Evaluator\n",
    "from nn_tools import torch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 150/150 [01:22<00:00,  1.82it/s]\n",
      "  0%|          | 0/51 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T11-T12': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 51/51 [00:26<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "train_studies, train_annotation, train_counter = construct_studies(\n",
    "    '../data/lumbar_train150', '../data/lumbar_train150_annotation.json')\n",
    "valid_studies, valid_annotation, valid_counter = construct_studies(\n",
    "    '../data/train/', '../data/lumbar_train51_annotation.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertebra_labels, disc_labels = [], []\n",
    "# for k, v in train_annotation.items():\n",
    "#     vertebra_labels.append(v[0])\n",
    "#     disc_labels.append(v[1])\n",
    "# vertebra_labels = torch.cat(vertebra_labels)\n",
    "# disc_labels = torch.cat(disc_labels)\n",
    "\n",
    "# from collections import Counter\n",
    "# vertebra_counter = Counter(vertebra_labels[:, -1].numpy().tolist())\n",
    "# vertebra_counter = torch.tensor([vertebra_counter[i] for i in range(len(vertebra_counter))], dtype=torch.float)\n",
    "# vertebra_weight = vertebra_counter.mean() / vertebra_counter\n",
    "# print(vertebra_weight)\n",
    "\n",
    "# disc_counter = Counter(disc_labels[:, -1].numpy().tolist())\n",
    "# disc_counter = torch.tensor([disc_counter[i] for i in range(len(disc_counter))], dtype=torch.float)\n",
    "# disc_weight = disc_counter.mean() / disc_counter\n",
    "# print(disc_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {k: len(v) for k, v in train_counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {k: len(v) for k, v in valid_counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DisDataLoader(train_studies, train_annotation, batch_size=8, sagittal_size=[512, 512],\n",
    "                                 transverse_size=[256, 256], k_nearest=1, num_workers=4, num_rep=20,\n",
    "                                 prob_rotate=1, max_angel=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for study_uid, study in train_studies.items():\n",
    "#     frame = study.t2_sagittal_middle_frame\n",
    "#     assert (study_uid, frame.series_uid, frame.instance_uid) in train_annotation\n",
    "\n",
    "# for study_uid, study in valid_studies.items():\n",
    "#     frame = study.t2_sagittal_middle_frame\n",
    "#     assert (study_uid, frame.series_uid, frame.instance_uid) in valid_annotation\n",
    "\n",
    "# for study_uid, study in train_studies.items():\n",
    "#     if study.t2_transverse_uid is None:\n",
    "#         print(study_uid)\n",
    "\n",
    "# for data, label in tqdm(train_dataloader, ascii=True):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = {}\n",
    "for study_uid, study in train_studies.items():\n",
    "    frame = study.t2_sagittal_middle_frame\n",
    "    train_images[(study_uid, frame.series_uid, frame.instance_uid)] = frame.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiseaseModel(\n",
       "  (backbone): KeyPointModelV2(\n",
       "    (backbone): BackboneWithFPN(\n",
       "      (body): IntermediateLayerGetter(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fpn): FeaturePyramidNetwork(\n",
       "        (inner_blocks): ModuleList(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (layer_blocks): ModuleList(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (extra_blocks): LastLevelMaxPool()\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0, inplace=True)\n",
       "      (1): Conv2d(256, 11, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (spinal_model): SpinalModel()\n",
       "    (cascade_heads): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Dropout(p=0, inplace=True)\n",
       "        (1): Linear(in_features=256, out_features=2, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Dropout(p=0, inplace=True)\n",
       "        (1): Linear(in_features=256, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (cascade_loss): SmoothL1Loss()\n",
       "    (spinal_model_base): SpinalModelBase()\n",
       "  )\n",
       "  (vertebra_head): Sequential(\n",
       "    (0): Dropout(p=0, inplace=True)\n",
       "    (1): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       "  (disc_head): Sequential(\n",
       "    (0): Dropout(p=0, inplace=True)\n",
       "    (1): Linear(in_features=256, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = resnet_fpn_backbone('resnet50', True)\n",
    "spinal_model = SpinalModel(train_images, train_annotation,\n",
    "                           num_candidates=128, num_selected_templates=8,\n",
    "                           max_translation=0.05, scale_range=[0.9, 1.1], max_angel=10)\n",
    "kp_model = KeyPointModelV2(backbone, len(SPINAL_VERTEBRA_ID), len(SPINAL_DISC_ID),\n",
    "                           pixel_mean=torch.tensor(0.5), pixel_std=torch.tensor(1), dropout=0,\n",
    "                           loss=KeyPointBCELossV2(lamb=1), spinal_model=spinal_model, loss_scaler=100,\n",
    "                           num_cascades=2\n",
    "                           ).cuda(0)\n",
    "dis_model = DiseaseModel(\n",
    "    kp_model, sagittal_size=[512, 512], loss_scaler=0.01, use_kp_loss=True, share_backbone=True\n",
    ").cuda(0)\n",
    "# dis_model = torch.nn.DataParallel(dis_model, device_ids=[0, 1])\n",
    "dis_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_studies, train_annotation, train_counter = construct_studies(\n",
    "#     '../data/small/', '../data/lumbar_train150_annotation.json')\n",
    "# small_dataloader = DisDataLoader(small_studies, train_annotation, batch_size=8, sagittal_size=[512, 512],\n",
    "#                                  transverse_size=[256, 256], k_nearest=1, num_workers=3, num_rep=10,\n",
    "#                                  prob_rotate=1, max_angel=180)\n",
    "# batch_data, batch_label = next(iter(small_dataloader))\n",
    "\n",
    "# visilize_coord(batch_data[0][0], batch_data[2][0])\n",
    "\n",
    "# batch_pred = dis_model(*batch_data)\n",
    "\n",
    "# tf.to_pil_image(batch_pred[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = Study('../data/lumbar_train150/study10/')\n",
    "# pred_coord, *_ = dis_model.eval().module(study)\n",
    "# human_coord = study.t2_sagittal_middle_frame.pixel_coord2human_coord(pred_coord.cpu())\n",
    "# human_coord\n",
    "# study.t2_transverse.point_distance(human_coord)\n",
    "# [dicom.image_position for dicom in study.t2_transverse]\n",
    "# study.t2_transverse.k_nearest(human_coord, 1, 8)\n",
    "# k_nearest = study.t2_transverse_k_nearest(pred_coord.cpu(), 2, [256, 256], 8)\n",
    "# k_nearest.shape\n",
    "# tf.to_pil_image(k_nearest[8][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using NullLoss as training loss, using NullLoss(higher is better) as early stopping metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 375/375 [01:39<00:00,  3.77it/s]\n",
      "100%|##########| 1020/1020 [00:58<00:00, 17.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 375 train NullLoss: 0.3456895649433136\n",
      "valid macro f1: 0.11663050384249678\n",
      "valid micro f1: 0.10184402905461612\n",
      "valid avg key point acc: 0.159950784663046\n",
      "valid macro precision: 0.3769636241674067\n",
      "valid disc v1 precision: 0.17266189405310114\n",
      "valid disc v2 precision: 0.290456448924776\n",
      "valid disc v3 precision: 0.3000000285714245\n",
      "valid disc v4 precision: 0.5164835128607664\n",
      "valid disc v5 precision: 0.277310961796477\n",
      "valid vertebra v1 precision: 0.5999999789473729\n",
      "valid vertebra v2 precision: 0.4818325440179291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 375/375 [01:41<00:00,  3.70it/s]\n",
      "100%|##########| 1020/1020 [00:59<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 750 train NullLoss: 0.11682767421007156\n",
      "valid macro f1: 0.10651488892341233\n",
      "valid micro f1: 0.12390269252631435\n",
      "valid avg key point acc: 0.14873584327171624\n",
      "valid macro precision: 0.37436403564142984\n",
      "valid disc v1 precision: 0.34482760404280416\n",
      "valid disc v2 precision: 0.19913422518318397\n",
      "valid disc v3 precision: 0.244186076257433\n",
      "valid disc v4 precision: 0.4571428693877516\n",
      "valid disc v5 precision: 0.04255328881844918\n",
      "valid vertebra v1 precision: 0.5223880563599916\n",
      "valid vertebra v2 precision: 0.8103161294403951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 375/375 [01:41<00:00,  3.69it/s]\n",
      "100%|##########| 1020/1020 [00:57<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1125 train NullLoss: 0.08557390421628952\n",
      "valid macro f1: 0.2037840898055412\n",
      "valid micro f1: 0.2343221397741601\n",
      "valid avg key point acc: 0.2630228812916918\n",
      "valid macro precision: 0.4311544587635584\n",
      "valid disc v1 precision: 0.4063745057221313\n",
      "valid disc v2 precision: 0.4157782551906928\n",
      "valid disc v3 precision: 0.273062747375443\n",
      "valid disc v4 precision: 0.5849056443574255\n",
      "valid disc v5 precision: 0.017751536360764927\n",
      "valid vertebra v1 precision: 0.5634517702079421\n",
      "valid vertebra v2 precision: 0.756756752130509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 375/375 [01:41<00:00,  3.70it/s]\n",
      "100%|##########| 1020/1020 [00:58<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1500 train NullLoss: 0.07829757779836655\n",
      "valid macro f1: 0.1848568152398223\n",
      "valid micro f1: 0.2211652856182101\n",
      "valid avg key point acc: 0.23787586551488596\n",
      "valid macro precision: 0.4324737644247196\n",
      "valid disc v1 precision: 0.5985130074902227\n",
      "valid disc v2 precision: 0.46300716167030254\n",
      "valid disc v3 precision: 0.1805054382306543\n",
      "valid disc v4 precision: 0.3863636621900768\n",
      "valid disc v5 precision: 0.06944450424381884\n",
      "valid vertebra v1 precision: 0.688311663855628\n",
      "valid vertebra v2 precision: 0.641170913292334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 375/375 [01:39<00:00,  3.77it/s]\n",
      "100%|##########| 1020/1020 [00:59<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1875 train NullLoss: 0.06678938120603561\n",
      "valid macro f1: 0.21801682853135992\n",
      "valid micro f1: 0.23348815827940772\n",
      "valid avg key point acc: 0.3003010984609384\n",
      "valid macro precision: 0.421848249117435\n",
      "valid disc v1 precision: 0.48059149794486145\n",
      "valid disc v2 precision: 0.11478600720677017\n",
      "valid disc v3 precision: 0.2843750134765617\n",
      "valid disc v4 precision: 0.6277372076296047\n",
      "valid disc v5 precision: 0.12376241348886995\n",
      "valid vertebra v1 precision: 0.6449999855000015\n",
      "valid vertebra v2 precision: 0.6766856185753758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 375/375 [01:40<00:00,  3.73it/s]\n",
      "100%|##########| 1020/1020 [00:58<00:00, 17.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2250 train NullLoss: 0.060649801045656204\n",
      "valid macro f1: 0.2541467784872816\n",
      "valid micro f1: 0.28256544167164216\n",
      "valid avg key point acc: 0.3360970841924703\n",
      "valid macro precision: 0.4414392490482601\n",
      "valid disc v1 precision: 0.5729166644965279\n",
      "valid disc v2 precision: 0.3234265796004693\n",
      "valid disc v3 precision: 0.047120442559139136\n",
      "valid disc v4 precision: 0.6136363464187354\n",
      "valid disc v5 precision: 0.2500000240384592\n",
      "valid vertebra v1 precision: 0.6465517115041628\n",
      "valid vertebra v2 precision: 0.6364229747203267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 375/375 [01:41<00:00,  3.68it/s]\n",
      "100%|##########| 1020/1020 [00:57<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2625 train NullLoss: 0.059307653456926346\n",
      "valid macro f1: 0.20352458156473294\n",
      "valid micro f1: 0.22257426357855098\n",
      "valid avg key point acc: 0.29890934080669646\n",
      "valid macro precision: 0.3842788624041819\n",
      "valid disc v1 precision: 0.5369003676420528\n",
      "valid disc v2 precision: 0.20445345326099382\n",
      "valid disc v3 precision: 0.038690503649374784\n",
      "valid disc v4 precision: 0.507812498779297\n",
      "valid disc v5 precision: 0.2331288671007525\n",
      "valid vertebra v1 precision: 0.5450980356785854\n",
      "valid vertebra v2 precision: 0.6238683107182171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 375/375 [01:40<00:00,  3.72it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cxt/anaconda3/envs/torch15/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/cxt/anaconda3/envs/torch15/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/cxt/anaconda3/envs/torch15/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/cxt/anaconda3/envs/torch15/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cxt/anaconda3/envs/torch15/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "    close()\n",
      "  File \"/home/cxt/anaconda3/envs/torch15/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/cxt/anaconda3/envs/torch15/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "100%|##########| 1020/1020 [00:58<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3000 train NullLoss: 0.053144317120313644\n",
      "valid macro f1: 0.26902734912373144\n",
      "valid micro f1: 0.2961275669767867\n",
      "valid avg key point acc: 0.3533634501407075\n",
      "valid macro precision: 0.44675514873089195\n",
      "valid disc v1 precision: 0.6294765804551906\n",
      "valid disc v2 precision: 0.247818507929546\n",
      "valid disc v3 precision: 0.14218011174501843\n",
      "valid disc v4 precision: 0.5151515128558314\n",
      "valid disc v5 precision: 0.23076926035502635\n",
      "valid vertebra v1 precision: 0.7900355665455113\n",
      "valid vertebra v2 precision: 0.5718545012301193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 375/375 [01:39<00:00,  3.77it/s]\n",
      "100%|##########| 1020/1020 [00:59<00:00, 17.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3375 train NullLoss: 0.05078485608100891\n",
      "valid macro f1: 0.27897641563776693\n",
      "valid micro f1: 0.3267467040870124\n",
      "valid avg key point acc: 0.37439219379463967\n",
      "valid macro precision: 0.4449820411963089\n",
      "valid disc v1 precision: 0.6077694208579093\n",
      "valid disc v2 precision: 0.2834645737491473\n",
      "valid disc v3 precision: 0.5172413785176377\n",
      "valid disc v4 precision: 0.2686567509467536\n",
      "valid disc v5 precision: 0.08715600117834851\n",
      "valid vertebra v1 precision: 0.7368420886426604\n",
      "valid vertebra v2 precision: 0.6137440744817053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 375/375 [01:40<00:00,  3.72it/s]\n",
      "100%|##########| 1020/1020 [00:58<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3750 train NullLoss: 0.04977820813655853\n",
      "valid macro f1: 0.3303986313022262\n",
      "valid micro f1: 0.3939307207056541\n",
      "valid avg key point acc: 0.4236565568806844\n",
      "valid macro precision: 0.47213611452656146\n",
      "valid disc v1 precision: 0.5372781056265538\n",
      "valid disc v2 precision: 0.3894878735987096\n",
      "valid disc v3 precision: 0.4130879381150128\n",
      "valid disc v4 precision: 0.3949044719866915\n",
      "valid disc v5 precision: 0.2622222433580228\n",
      "valid vertebra v1 precision: 0.5236686376527433\n",
      "valid vertebra v2 precision: 0.7843035313481962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 375/375 [01:40<00:00,  3.72it/s]\n",
      "100%|##########| 1020/1020 [00:57<00:00, 17.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4125 train NullLoss: 0.04714526981115341\n",
      "valid macro f1: 0.34386695961157\n",
      "valid micro f1: 0.4135737026652078\n",
      "valid avg key point acc: 0.46656877393888363\n",
      "valid macro precision: 0.4643366540622344\n",
      "valid disc v1 precision: 0.6077812805934536\n",
      "valid disc v2 precision: 0.16775885536674037\n",
      "valid disc v3 precision: 0.18525521038732667\n",
      "valid disc v4 precision: 0.602150526650481\n",
      "valid disc v5 precision: 0.2629482260599023\n",
      "valid vertebra v1 precision: 0.5421994863325071\n",
      "valid vertebra v2 precision: 0.8822629930452295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 375/375 [01:40<00:00,  3.74it/s]\n",
      "100%|##########| 1020/1020 [00:58<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4500 train NullLoss: 0.045596715062856674\n",
      "valid macro f1: 0.31970403482447346\n",
      "valid micro f1: 0.3618046458384217\n",
      "valid avg key point acc: 0.42213283407584395\n",
      "valid macro precision: 0.4602354489411279\n",
      "valid disc v1 precision: 0.710526310971938\n",
      "valid disc v2 precision: 0.5405007351840726\n",
      "valid disc v3 precision: 0.1670146276820615\n",
      "valid disc v4 precision: 0.38888890123456654\n",
      "valid disc v5 precision: 0.0796460548985792\n",
      "valid vertebra v1 precision: 0.7242424106519751\n",
      "valid vertebra v2 precision: 0.6108291019647027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 375/375 [01:39<00:00,  3.78it/s]\n",
      "100%|##########| 1020/1020 [00:58<00:00, 17.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4875 train NullLoss: 0.044691555202007294\n",
      "valid macro f1: 0.3518974231412559\n",
      "valid micro f1: 0.424821003864251\n",
      "valid avg key point acc: 0.47372614678142594\n",
      "valid macro precision: 0.4623134867622703\n",
      "valid disc v1 precision: 0.6102175948870843\n",
      "valid disc v2 precision: 0.2574385573754578\n",
      "valid disc v3 precision: 0.4477611959790599\n",
      "valid disc v4 precision: 0.3945946059897723\n",
      "valid disc v5 precision: 0.08914731867075049\n",
      "valid vertebra v1 precision: 0.6934097310366917\n",
      "valid vertebra v2 precision: 0.7436254033970755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 375/375 [01:40<00:00,  3.71it/s]\n",
      " 56%|#####6    | 574/1020 [00:32<00:26, 17.11it/s]"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(\n",
    "    dis_model, valid_studies, '../data/lumbar_train51_annotation.json', num_rep=20, max_dist=6,\n",
    "#     metric='macro precision'\n",
    ")\n",
    "optimizer = torch.optim.AdamW(dis_model.parameters(), lr=1e-5)\n",
    "max_step = 50*len(train_dataloader)\n",
    "fit_result = torch_utils.fit(\n",
    "    dis_model,\n",
    "    train_data=train_dataloader,\n",
    "    valid_data=None,\n",
    "    optimizer=optimizer,\n",
    "    max_step=max_step,\n",
    "    loss=NullLoss(),\n",
    "    metrics=[NullLoss()],\n",
    "    is_higher_better=True,\n",
    "    evaluate_per_steps=len(train_dataloader),\n",
    "    evaluate_fn=evaluator,\n",
    "    checkpoint_dir='../models',\n",
    "#     early_stopping=5*len(train_dataloader),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 5100/5100 [03:04<00:00, 27.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('macro f1', 0.6117107510148846),\n",
       " ('micro f1', 0.7109671186430598),\n",
       " ('avg key point acc', 0.8585061880156308),\n",
       " ('macro precision', 0.5431540563052295),\n",
       " ('disc v1 precision', 0.7410078856683826),\n",
       " ('disc v2 precision', 0.5044110818622162),\n",
       " ('disc v3 precision', 0.33070411761945323),\n",
       " ('disc v4 precision', 0.5620817834634679),\n",
       " ('disc v5 precision', 0.1303009601210605),\n",
       " ('vertebra v1 precision', 0.7496183190863004),\n",
       " ('vertebra v2 precision', 0.7839542463157259)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_model.kp_model = torch.load('../models/2020070102.kp_model_v2', map_location='cuda:0')\n",
    "evaluator = Evaluator(dis_model, valid_studies, '../data/lumbar_train51_annotation.json',\n",
    "                      num_rep=100, max_dist=6)\n",
    "evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(dis_model.cpu(), '../models/2020070103.dis_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 50/50 [00:34<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# testA_studies = construct_studies('../data/lumbar_testA50/')\n",
    "\n",
    "# result = []\n",
    "# for study in tqdm(testA_studies.values(), ascii=True):\n",
    "#     result.append(dis_model.eval()(study, True))\n",
    "\n",
    "# i = 9\n",
    "# visilize_annotation(testA_studies[result[i]['studyUid']].t2_sagittal_middle_frame.image, result[i])\n",
    "\n",
    "# with open('../predictions/2020070102.json', 'w') as file:\n",
    "#     json.dump(result, file)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch15",
   "language": "python",
   "name": "torch15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
